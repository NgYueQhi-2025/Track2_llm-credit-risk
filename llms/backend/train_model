#README: pip install scikit-learn
#Train pipeline: reads artifacts/features.csv and an optional structured CSV, trains LogisticRegression & RandomForest

import os
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Module-level paths so functions can reference them
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# Paths for artifacts, model and scaler
ARTIFACTS_DIR = os.path.join(BASE_DIR, 'artifacts')
MODEL_PATH = os.path.join(ARTIFACTS_DIR, 'model.joblib')
SCALER_PATH = os.path.join(ARTIFACTS_DIR, 'scaler.joblib')

def load_features(tabular_csv: str | None = None):
	import pandas as pd

	# Load features.csv
	features_path = os.path.join(BASE_DIR, 'artifacts', 'features.csv')
	df = pd.read_csv(features_path)

	# Optionally merge with tabular_csv
	if tabular_csv:
		tabular_df = pd.read_csv(tabular_csv)
		df = df.merge(tabular_df, how='left', left_index=True, right_index=True)

	# Ensure columns are numeric or set to 0.0 if missing
	for col in ['sentiment_score', 'risky_phrase_count', 'contradiction_flag', 'credibility_score']:
		if col in df.columns:
			df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)
		else:
			df[col] = 0.0

	return df

	# The following block is duplicated and references 'df' outside its scope, so it should be removed.






def train_and_save(tabular_csv: str | None = None, choose_model: str = 'random_forest'):
	#Train models and save selected model + scaler. choose_model: 'random_forest' or 'logistic'.
	#Returns a dict with training metrics.

	df = load_features(tabular_csv)

	feature_cols = ['sentiment_score', 'risky_phrase_count', 'contradiction_flag', 'credibility_score']
	X = df[feature_cols]
	y = df['label']

	scaler = StandardScaler()
	Xs = scaler.fit_transform(X)

	X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2, random_state=42, stratify=y)

	# Models
	lr = LogisticRegression(random_state=42, max_iter=1000)
	rf = RandomForestClassifier(random_state=42, n_estimators=200)

	lr.fit(X_train, y_train)
	rf.fit(X_train, y_train)

	# Evaluate both
	results = {}
	for name, model in (('logistic', lr), ('random_forest', rf)):
		preds = model.predict(X_test)
		acc = accuracy_score(y_test, preds)
		report = classification_report(y_test, preds, zero_division=0)
		results[name] = {'accuracy': float(acc), 'report': report}

	# Choose model to save
	chosen = rf if choose_model == 'random_forest' else lr

	# Save model and scaler
	os.makedirs(os.path.join(BASE_DIR, 'artifacts'), exist_ok=True)
if __name__ == '__main__':
	print('Training with demo settings...')
	res = train_and_save()
	print('Training results:')
	for m, info in res['models'].items():
		print('Model:', m)
		print('Accuracy:', info['accuracy'])
		print(info['report'])
		print('Saved model to', res['model_path'])
		print('Saved scaler to', res['scaler_path'])
		print('Saved model to', res['model_path'])
		print('Saved scaler to', res['scaler_path'])
